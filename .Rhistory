## Remove unnecessary columns (threshold, const_err,s9_id, t_stamp),
## and slice data to only sample top 30 meters of water column to represent
## the mixed layer.
subset(SST, select = -c(threshold, const_err, s9_id, t_stamp))
## Install necessary libraries
library(ggplot2)
library(dplyr)
## Import data from raw csv and attach for quick data retrieval, accounting for unnecessary
## V1, V2, V3 etc header names.
SST_original <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/SST.csv",
header=TRUE)
## Remove unnecessary columns (threshold, const_err,s9_id, t_stamp),
## and slice data to only sample top 30 meters of water column to represent
## the mixed layer.
SST_columnedit <- subset(SST, select = -c(threshold, const_err, s9_id, t_stamp))
## Remove unnecessary columns (threshold, const_err,s9_id, t_stamp),
## and slice data to only sample top 30 meters of water column to represent
## the mixed layer.
SST_columnedit <- subset(SST_original, select = -c(threshold, const_err, s9_id, t_stamp))
## Remove unnecessary columns (threshold, const_err,s9_id, t_stamp),
## and slice data to only sample top 30 meters of water column to represent
## the mixed layer.
SST_columnedit <- subset(SST_original, select = -c(threshold, const_err, s9_id, t_stamp))
SST_depthedit <- subset(SST_columnedit, SST_columnedit$depth <= 30)
SST_depthedit
## Check that depth range is accurate
range(SST_depthedit$depth)
## Check that depth range is accurate
arrange(SST_depthedit$depth)
## Check that depth range is accurate
nchar(SST_depthedit$depth)
## Check that depth range is accurate
depth_truth <- nchar(SST_depthedit$depth)
?nchar
if(depth_truth > 2){
print("Depth")
}
sum(depth_truth > 2)
sum(depth_truth > 1)
source('~/EM_TimeSeries/SST_Timeseries_W17.R')
head(SST_depthedit)
## Add two more columns that will hold data for temperature at 5m depth, and 23m depth.
mutate(SST_depthedit, temp_5 = (SST_depthedit$depth == 5))
mutate(SST_depthedit, temp_23 = (SST_depthedit$depth == 23))
SST_added = within(SST_depthedit, {
temp_5 = ifelse(SST_depthedit$depth == 5, (SST_depthedit$temperature), "NA")
temp_23 = ifelse(SST_depthedit$depth == 23, (SST_depthedit$temperature), "NA")
})
head(SST_added)
source('~/EM_TimeSeries/SST_Timeseries_W17.R')
print(SST_timeseries + ggtitle("Temperatures"))
## Graph
SST_timeseries <- ggplot(SST_added, aes(x = SST_added$d_stamp)) +
geom_line(aes(y = SST_added$temp_5), color="firebrick2") +
geom_line(aes(y = SST_added$temp_23), color = "deeporchid4") +
ylab(label="Date") +
xlab("Temperature in C")
suppressWarnings(SST_timeseries)
## Graph
SST_timeseries <- ggplot(SST_added, aes(x = SST_added$d_stamp)) +
geom_line(aes(y = SST_added$temp_5), color="firebrick2") +
geom_line(aes(y = SST_added$temp_23), color = "blue") +
ylab(label="Date") +
xlab("Temperature in C")
suppressWarnings(SST_timeseries)
print(SST_timeseries + ggtitle("Temperatures"))
print(SST_timeseries + ggtitle("Temperatures"))
## Graph
SST_timeseries <- ggplot(SST_added, aes(x = SST_added$d_stamp)) +
geom_line(aes(y = SST_added$temp_5), color="firebrick2") +
geom_line(aes(y = SST_added$temp_23), color = "blue") +
ylab(label="Date") +
xlab("Temperature in C")
## Graph
ggplot(SST_added, aes(x = SST_added$d_stamp)) +
geom_line(aes(y = SST_added$temp_5), color="firebrick2") +
geom_line(aes(y = SST_added$temp_23), color = "blue") +
ylab(label="Date") +
xlab("Temperature in C")
## Graph
SST_timeseries <- ggplot(SST_added, aes(x = SST_added$d_stamp)) +
geom_line(aes(y = SST_added$temp_5), color="firebrick2") +
geom_line(aes(y = SST_added$temp_23), color = "blue") +
ylab(label="Date") +
xlab("Temperature in C")
suppressWarnings(SST_timeseries)
print(SST_timeseries + ggtitle("Temperatures"))
## Graph
## Create object containing graphical data
rm(SST_timeseries)
SST_beta <- subset(SST_added, select = -c(depth, temperature))
attach(SST_beta)
temp_5
max(temp_5)
## Graph
ggplot(SST_beta, aes(x = SST_beta$d_stamp)) +
geom_line(aes(y = SST_beta$temp_5), colour="blue") +
geom_line(aes(y = SST_beta$temp_23), colour = "grey") +
ylab(label="temp") +
xlab("date")
SST_beta
SST_added
## Average temperature data to the daily mean, and round to whole numbers
#temp_daily_avg <- aggregate(.~d_stamp, FUN=mean, data=SST_edit2)
#temp_daily_avg$temperature<-round(temp_daily_avg$temperature)
SST_temp_avg <- aggregate(.~d_stamp, FUN = mean, data = SST_beta)
head(SST_temp_avg)
## Develop new columns that hold data for temperature at specific depth.
SST_added = within(SST_depthedit, {
temp_5 = ifelse(SST_depthedit$depth == 5, (SST_depthedit$temperature), "0")
temp_23 = ifelse(SST_depthedit$depth == 23, (SST_depthedit$temperature), "0")
})
## Clean up set by only including lines that will be graphed
SST_beta <- subset(SST_added, select = -c(depth, temperature))
SST_added
?na.rm
source('~/EM_TimeSeries/SST_Timeseries_W17.R')
head(SST_temp_avg)
SST3
########
mutate(SST2, temp5 = (SST2$depth == 5))
## Install necessary libraries
library(ggplot2)
## SST Time Series
## R. Lionheart
## Install necessary libraries
library(ggplot2)
library(dplyr)
## Import data from raw csv and attach for quick data retrieval, accounting for unnecessary
## V1, V2, V3 etc header names.
SST_original <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/SST.csv",
header=TRUE)
###################### FIND TEMPERATURE OUTLIERS
###################### Numerically check depth data
## Remove unnecessary columns (threshold, const_err,s9_id, t_stamp),
## and slice data to only sample top 30 meters of water column to represent
## the mixed layer.
SST_columnedit <- subset(SST_original, select = -c(threshold, const_err, s9_id, t_stamp))
SST_depthedit <- subset(SST_columnedit, SST_columnedit$depth <= 30)
## Check that depth range is accurate (i.e, that we are only integrating measurements
## from two depths, 5m and 23m)
depth_truth <- nchar(SST_depthedit$depth)
sum(depth_truth > 2)
## Add two more columns that will hold data for temperature at 5m depth, and 23m depth.
mutate(SST_depthedit, temp_5 = (SST_depthedit$depth == 5))
mutate(SST_depthedit, temp_23 = (SST_depthedit$depth == 23))
## Develop new columns that hold data for temperature at specific depth.
SST_added = within(SST_depthedit, {
temp_5 = ifelse(SST_depthedit$depth == 5, (SST_depthedit$temperature), "0")
temp_23 = ifelse(SST_depthedit$depth == 23, (SST_depthedit$temperature), "0")
})
## Clean up set by only including lines that will be graphed
SST_beta <- subset(SST_added, select = -c(depth, temperature))
SST_added
attach(SST_beta)
mydata$v1[mydata$v1==99] <- NA
## Average temperature data to the daily mean, and round to whole numbers
#temp_daily_avg <- aggregate(.~d_stamp, FUN=mean, data=SST_edit2)
#temp_daily_avg$temperature<-round(temp_daily_avg$temperature)
SST_temp_avg <- aggregate(.~d_stamp, FUN = mean, data = SST_beta)
head(SST_temp_avg)
## Create object containing graphical data
#SST_timeseries <- ggplot(SST_added, aes(x=SST_added$d_stamp, y=SST_added$temperature, group=1)) +
#  geom_line(color='firebrick2') +
#  geom_point(color='firebrick4') +
#  labs(x="Date", y="Average temperature per day in C")
#  scale_x_discrete(breaks = unique(temp_daily_avg$d_stamp)[seq(1,124,7)])
#suppressWarnings(SST_timeseries)
#print(SST_timeseries + ggtitle("Temperature in the Eastern Mediterranean"))
########
mutate(SST2, temp5 = (SST2$depth == 5))
mutate(SST2, temp23 = (SST2$depth == 23))
## Average temperature data to the daily mean, and round to whole numbers
temp_daily_avg <- aggregate(.~d_stamp, FUN=mean, data=SST_edit2)
temp_daily_avg$temperature<-round(temp_daily_avg$temperature)
range(SST2$temperature)
print(SST_timeseries + ggtitle("Temperature in the Eastern Mediterranean"))
########
mutate(SST2, temp5 = (SST2$depth == 5))
mutate(SST2, temp23 = (SST2$depth == 23))
## Import data from raw csv and attach for quick data retrieval. Remove unneccessary
## V1, V2 column names.
SST <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/SST.csv",
header=TRUE)
## Average temperature data to the daily mean, and round to whole numbers
temp_daily_avg <- aggregate(.~d_stamp, FUN=mean, data=SST_edit2)
temp_daily_avg$temperature<-round(temp_daily_avg$temperature)
range(SST2$temperature)
SST3 = within(SST2, {
temp5 = ifelse(SST2$depth == 5, (SST2$temperature), 0)
temp23 = ifelse(SST2$depth == 23, (SST2$temperature), 0)
})
SST3
SST2 = within(SST2, {
})
## Create object containing graphical data
SST_timeseries <- ggplot(temp_daily_avg, aes(x=temp_daily_avg$d_stamp, y=temp_daily_avg$temperature, group=1)) +
geom_line(color='firebrick2') +
geom_point(color='firebrick4') +
labs(x="Date", y="Average temperature per day in C")
scale_x_discrete(breaks = unique(temp_daily_avg$d_stamp)[seq(1,124,7)])
suppressWarnings(SST_timeseries)
print(SST_timeseries + ggtitle("Temperature in the Eastern Mediterranean"))
library(dplyr)
## Install necessary libraries
library(ggplot2)
library(dplyr)
## Import data from raw csv and attach for quick data retrieval, accounting for unnecessary
## V1, V2, V3 etc header names.
SST_original <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/SST.csv",
header=TRUE)
## Remove unnecessary columns (threshold, const_err,s9_id, t_stamp),
## and slice data to only sample top 30 meters of water column to represent
## the mixed layer.
SST_columnedit <- subset(SST_original, select = -c(threshold, const_err, s9_id, t_stamp))
SST_depthedit <- subset(SST_columnedit, SST_columnedit$depth <= 30)
## Check that depth range is accurate (i.e, that we are only integrating measurements
## from two depths, 5m and 23m)
depth_truth <- nchar(SST_depthedit$depth)
sum(depth_truth > 2)
## Add two more columns that will hold data for temperature at 5m depth, and 23m depth.
mutate(SST_depthedit, temp_5 = (SST_depthedit$depth == 5))
mutate(SST_depthedit, temp_23 = (SST_depthedit$depth == 23))
## Develop new columns that hold data for temperature at specific depth.
SST_added = within(SST_depthedit, {
temp_5 = ifelse(SST_depthedit$depth == 5, (SST_depthedit$temperature), "0")
temp_23 = ifelse(SST_depthedit$depth == 23, (SST_depthedit$temperature), "0")
})
## Clean up set by only including lines that will be graphed
SST_beta <- subset(SST_added, select = -c(depth, temperature))
SST_added
attach(SST_beta)
head(SST_temp_avg)
rm(SST_temp_avg)
SST_added
vignette(dplyr)
library(dplyr)
vignette(dplyr)
vignette(dplyr)
## Install necessary libraries
library(ggplot2)
library(dplyr)
## Import data from raw csv
chlorophyll <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/chlorophyll.csv",
header=TRUE)
## Remove unnecessary columns (threshold, const_err, chl_avg)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err, chl_avg))
chlorophyll_edit
chlorophyll
## Remove unnecessary columns (threshold, const_err, chl_avg)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err, chl_avg))
chlorophyll_edit
## Remove unnecessary columns (threshold, const_err, chl_avg)
subset(chlorophyll, select = -c(threshold, const_err, chl_avg))
head(chlorophyll)
## Average chlorophyll and turbidity data to the daily mean
chl_day_avg <- aggregate(.~d_stamp, FUN=mean, data=chlorophyll)
## Average chlorophyll and turbidity data to the daily mean
chl_day_avg <- aggregate(.~d_stamp, FUN=mean, data=chlorophyll)
attach(chlorophyll)
attach(chlorophyll)
## Import data from raw csv
chlorophyll <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/chlorophyll.csv",
header=TRUE)
## Remove unnecessary columns (threshold, const_err, chl_avg)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err, chl_avg))
## Remove unnecessary columns (threshold, const_err)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err, chl_avg))
## Remove unnecessary columns (threshold, const_err)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err))
## Average chlorophyll and turbidity data to the daily mean
chl_day_avg <- aggregate(.~d_stamp, FUN=mean, data=chlorophyll_edit)
## Use position dodge to avoid points overlapping
pd <- position_dodge(0.08)
## Create object containing graphical data
chl_timeseries <- ggplot(chl_day_avg, aes(x=d_stamp, y=chlorophyll_concentration, group=1)) +
geom_line(color='seagreen') +
geom_point(color='seagreen4') +
labs(x="Date", y="Chlorophyll Concentration in ug/L") +
scale_x_discrete(breaks = unique(chl_day_avg$d_stamp)[seq(1,138,14)])
suppressWarnings(chl_timeseries)
print(chl_timeseries + ggtitle("Chlorophyll Concentrations in the Eastern Mediterranean"))
SST3
print(csv)
csv
csv <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/SST.csv",
header=TRUE)
csv
typeof(csv)
csv[1]
csv[1][1]
## Chlorophyll Time Series
## R. Lionheart
## Install necessary libraries
library(ggplot2)
library(dplyr)
attach(chlorophyll)
## Import data from raw csv
chlorophyll <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/chlorophyll.csv",
header=TRUE)
## Remove unnecessary columns (threshold, const_err)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err))
## Average chlorophyll and turbidity data to the daily mean
chl_day_avg <- aggregate(.~d_stamp, FUN=mean, data=chlorophyll_edit)
## Use position dodge to avoid points overlapping
pd <- position_dodge(0.08)
## Create object containing graphical data
chl_timeseries <- ggplot(chl_day_avg, aes(x=d_stamp, y=chlorophyll_concentration, group=1)) +
geom_line(color='seagreen') +
geom_point(color='seagreen4') +
labs(x="Date", y="Chlorophyll Concentration in ug/L") +
scale_x_discrete(breaks = unique(chl_day_avg$d_stamp)[seq(1,138,14)])
suppressWarnings(chl_timeseries)
print(chl_timeseries + ggtitle("Chlorophyll Concentrations in the Eastern Mediterranean"))
source('~/EM_TimeSeries/SST_Timeseries_W17.R')
## Install necessary libraries
library(ggplot2)
library(dplyr)
attach(chlorophyll)
## Import data from raw csv
chlorophyll <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/chlorophyll.csv",
header=TRUE)
source('~/EM_TimeSeries/SST_Timeseries_W17.R')
?aggregate
print(chl_timeseries + ggtitle("Chlorophyll Concentrations in the Eastern Mediterranean"))
print(chl_timeseries + ggtitle("Winter Chlorophyll Concentrations in the Eastern Mediterranean"))
## Create object containing graphical data
chl_timeseries <- ggplot(chl_day_avg, aes(x=d_stamp, y=chlorophyll_concentration, color=chlorophyll_concentration, group=1)) +
geom_line(color='darkblue') +
geom_point(color='black') +
labs(x="Date", y="Chlorophyll Concentration in ug/L") +
scale_x_discrete(breaks = unique(chl_day_avg$d_stamp)[seq(1,138,14)])
suppressWarnings(chl_timeseries)
print(chl_timeseries + ggtitle("Winter Chlorophyll Concentrations in the Eastern Mediterranean"))
## Chlorophyll Time Series
## R. Lionheart
## Install necessary libraries
library(ggplot2)
library(dplyr)
attach(chlorophyll)
## Import data from raw csv
chlorophyll <- read.csv("/Users/regina/Downloads/Sensors_1524643808500/chlorophyll.csv",
header=TRUE)
## Remove unnecessary columns (threshold, const_err)
chlorophyll_edit <- subset(chlorophyll, select = -c(threshold, const_err))
## Average chlorophyll and turbidity data to the daily mean
chl_day_avg <- aggregate(.~d_stamp, FUN=mean, data=chlorophyll_edit)
## Use position dodge to avoid points overlapping
pd <- position_dodge(0.08)
## Create object containing graphical data
chl_timeseries <- ggplot(chl_day_avg, aes(x=d_stamp, y=chlorophyll_concentration, group=1)) +
geom_line(color='seagreen') +
geom_point(color='seagreen4') +
labs(x="Date", y="Chlorophyll Concentration in ug/L") +
scale_x_discrete(breaks = unique(chl_day_avg$d_stamp)[seq(1,138,14)])
suppressWarnings(chl_timeseries)
print(chl_timeseries + ggtitle("Chlorophyll Concentrations in the Eastern Mediterranean"))
avg(chlorophyll$chlorophyll_concentration)
mean(chlorophyll$chlorophyll_concentration)
a <-myfunc(as.Date("2017-10-01"),as.Date("2018-03-15"))
a <-chlorophyll(as.Date("2017-10-01"),as.Date("2018-03-15"))
subset(chlorophyll, d_stamp > "2017-10-01" & date < "2018-03-15")
num_date <- as.numeric(chlorophyll$d_stamp)
subset(num_date, d_stamp > "2017-10-01" & date < "2018-03-15")
num_date
median(chlorophyll$chlorophyll_concentration)
install.packages(ncdf4)
install.packages("ncdf4")
nc_open(/Users/regina/university_projects/copernicus
, write=FALSE, readunlim=TRUE, verbose=FALSE,
auto_GMT=TRUE, suppress_dimvals=FALSE )
nc_open("/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc"
, write=FALSE, readunlim=TRUE, verbose=FALSE,
auto_GMT=TRUE, suppress_dimvals=FALSE )
data_test <- nc_open("/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc"
, write=FALSE, readunlim=TRUE, verbose=FALSE,
auto_GMT=TRUE, suppress_dimvals=FALSE )
library(ncdf4)
# open a netCDF file
ncin <- nc_open("/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
print(ncin)
lon <- ncvar_get(ncin,"lon")
nlon <- dim(lon)
nlong
nlon
head(lon)
lat <- ncvar_get(ncin,"lat",verbose=F)
nlat <- dim(lat)
head(lat)
nlat
print(c(nlon,nlat))
t <- ncvar_get(ncin,"time")
t
tunits <- ncatt_get(ncin,"time","units")
nt <- dim(t)
nt
tunits
ncin
rm(ncin)
ncin
# open a netCDF file
copernicus_data <- nc_open("/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
print(copernicus_data)
temp <- get.var.ncdf(temp.nc,"air")
chl_lon <- ncvar_get(copernicus_data,"lon")
chl_lon
head(chl_lon)
?ncvar_get
chl_lat <- ncvar_get(copernicus_data,"lat",verbose=F)
head(chl_lat)
print(c(chl_lon,chl_lat))
as.data.frame(c(chl_lon,chl_lat))
head(as.data.frame(c(chl_lon,chl_lat)))
head(chl_lon)
head(chl_lon)
head(chl_lat)
print(c(chl_lon,chl_lat))
head(copernicus_data)
print(copernicus_data)
head(chl_lon)
head(chl_lat)
print(c(chl_lon,chl_lat))
nlon <- dim(chl_lon)
nlat <- dim(chl_lat)
print(c(nlon,nlat))
t <- ncvar_get(copernicus_data,"time")
t
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
install.packages("raster")
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(rgdal) # package for geospatial analysis
install.packages("rgdal")
library(rgdal) # package for geospatial analysis
library(ggplot2) # package for plotting
## open a netCDF file
copernicus_data <- nc_open("/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
print(copernicus_data)
# Save the print(nc) dump to a text file
{
sink('/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01_metadata.txt')
print(nc_data)
sink()
}
# Save the print(nc) dump to a text file
{
sink('/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01_metadata.txt')
print(copernicus_data)
sink()
}
View(chl_timeseries)
# Save the print(nc) dump to a text file
{
sink('/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01_metadata.txt')
print(copernicus_data)
sink()
}
copernicus_data
copernicus_data
print(copernicus_data)
## open a netCDF file
copernicus_chl <- nc_open("/Users/regina/university_projects/copernicus/data/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
print(copernicus_chl)
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(rgdal) # package for geospatial analysis
library(ggplot2) # package for plotting
cop_chl <- nc_open('/Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc')
cop_chl <- nc_open('/Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc')
cop_chl <- nc_open("Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
cop_chl <- nc_open("/Users/regina/university_projects/copernicus")
cop_chl <- nc_open("/Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
cop_chl <- nc_open("/Users/regina/university_projects/copernicus")
cop_chl <- nc_open("Users/regina/university_projects/copernicus")
cop_chl <- nc_open("Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc")
cop_chl <- nc_open(file.choose("Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc"),
verbose = TRUE, write = FALSE)
cop_chl <- nc_open(file.choose("Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc"),
verbose = TRUE, write = FALSE)
cop_chl
print(cop_chl)
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(rgdal) # package for geospatial analysis
library(ggplot2) # package for plotting
cop_chl <- nc_open(file.choose("Users/regina/university_projects/copernicus/COP_L3_CHL_D_1km_daily_30_38_24_36_2017-10-01.nc"),
verbose = TRUE, write = FALSE)
lon <- ncvar_get(cop_chl, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
lat <- ncvar_get(cop_chl, "lat", verbose = F)
t <- ncvar_get(cop_chl, "time")
head(lon) # look at the first few entries in the longitude vector
lon
dim(lon)
dim(lon)
df <- ("1, 2, 3, 4")
df
v <- c(1,2,3,4)
v
sink()
v
head(lon) # look at the first few entries in the longitude vector
chlorophyll_a <- get.var.ncdf(CHL.nc,"chl")
counts <- table(mtcars$gear)
barplot(counts, main="Car Distribution", horiz=TRUE,
names.arg=c("3 Gears", "4 Gears", "5 Gears"))
counts
barplot(counts, main="Languages Spoken", horiz=TRUE,
names.arg=c("Bilingual", "Trilingual", "Multilingual"))
barplot(counts, main="Languages Spoken", horiz=TRUE,
names.arg=c("Two", "Three", "Four"))
